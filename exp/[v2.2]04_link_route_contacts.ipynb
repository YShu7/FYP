{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sqlite3\n",
    "import operator\n",
    "import pandas as pd\n",
    "import collections\n",
    "import networkx as nx\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "utils = __import__('utils.utils', fromlist=['object'])\n",
    "train = __import__('utils.train', fromlist=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect('../corona-sniffer/backend/data/database_100-_test.db')\n",
    "\n",
    "df_walks = pd.read_sql_query(\"SELECT * FROM walks JOIN walkers ON walkers.id = walks.walker_id\", cnx)\n",
    "df_walkers = pd.read_sql_query(\"SELECT * FROM walkers\", cnx)\n",
    "df_agents = pd.read_sql_query(\"SELECT * FROM agents\", cnx)\n",
    "df_contacts_tmp = pd.read_sql_query(\"SELECT * FROM contacts\", cnx)\n",
    "idx = df_contacts_tmp.groupby(['walker_id', 'time'])['distance'].transform(max) == df_contacts_tmp['distance']\n",
    "df_contacts = df_contacts_tmp[idx]\n",
    "\n",
    "INTERVAL = 60\n",
    "TIME_PERIOD = 1\n",
    "SCALE_METERS = 15000\n",
    "scaleMeters = SCALE_METERS * 0.2\n",
    "SIGMA_V = scaleMeters / 100\n",
    "IMPOSSIBLE = 1e-10\n",
    "MINUTE = 10\n",
    "UPDATE_TIME = MINUTE * INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_pos, pos_to_id = utils.get_position(df_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53752 15400\n"
     ]
    }
   ],
   "source": [
    "print(df_contacts_tmp.shape[0], df_contacts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_agent_id, prob_dir, prob_move = utils.get_agent_next_prob(df_walkers, df_contacts)\n",
    "prob_pos = utils.map_prob_to_pos(prob_agent_id, id_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# agent_id -> next_agent_id\\nsparse data\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# agent_id -> next_agent_id\n",
    "sparse data\n",
    "\"\"\"\n",
    "# print(collections.Counter([i for dic in prob_agent_id.values() for _, i in dic.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1927"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_contacts['walker_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\"\"\"\n",
    "Map agent id to its most possible next agent.\n",
    "\"\"\"\n",
    "link_list = {}\n",
    "visited_walker_ids = set()\n",
    "\n",
    "def train(walker_id1):\n",
    "    posX, posY, negX, negY = [], [], [], []\n",
    "    time1, time2 = utils.get_last_2_time(df_contacts, walker_id1)\n",
    "\n",
    "    if not time1 or not time2:\n",
    "        return #continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # in case there're multiple agents tracking the walker\n",
    "    last_rows = df_contacts.loc[(df_contacts['walker_id'] == walker_id1) & (df_contacts['time'] == time1)]\n",
    "    pre_rows = df_contacts.loc[(df_contacts['walker_id'] == walker_id1) & (df_contacts['time'] == time2)]\n",
    "    if last_rows.shape[0] == 0 or pre_rows.shape[0] == 0:\n",
    "        return #continue\n",
    "        \n",
    "    if DEBUG: print('walker_id1: {}, # last_rows: {}, # pre_rows: {}'.format(walker_id1, last_rows.shape, pre_rows.shape))\n",
    "        \n",
    "    # among all the tracked records, consider mean velocity as real velocity\n",
    "    vx, vy = utils.get_mean_v(last_rows, pre_rows)\n",
    "    avg_dis = math.sqrt(vx ** 2 + vy ** 2)\n",
    "    if DEBUG: print('velocity: ', time.time() - start_time)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # get candidate points by time\n",
    "    candidates = df_contacts.loc[(pd.to_numeric(df_contacts[\"time\"]) < (int(time1) + 100)) & \n",
    "                                 (pd.to_numeric(df_contacts[\"time\"]) > (int(time1))) & \n",
    "                                 (df_contacts['walker_id'] != walker_id1)]\n",
    "#     next_time = candidates['time'].min()\n",
    "#     candidates = candidates.loc[candidates['time'] == next_time]\n",
    "    # idx = groupby(['walker_id'])['time'].transform(lambda x: pd.to_numeric(x).min()) == pd.to_numeric(candidates['time'])\n",
    "    # candidates = candidates[idx]\n",
    "    if DEBUG: print(f'{candidates.shape}: ', time.time() - start_time)\n",
    "    \n",
    "    if candidates.shape[0] == 0:\n",
    "        return #continue\n",
    "    \n",
    "    candidate_agent_probs = {}\n",
    "    for _, row1 in last_rows.iterrows():\n",
    "        start_time = time.time()\n",
    "        \n",
    "        agent_id1, time1 = row1['agent_id'], row1['time']\n",
    "        json1 = json.loads(row1['json'])['agentPos']\n",
    "    \n",
    "        for _, row2 in candidates.iterrows():\n",
    "            res = ''\n",
    "            agent_id2, walker_id2, time2 = row2['agent_id'], row2['walker_id'], row2['time']\n",
    "            json2 = json.loads(row2['json'])['agentPos']\n",
    "            \n",
    "            isPos, thisX = True, []\n",
    "            if df_walks.loc[df_walks['walker_id'] == walker_id1].iloc[0]['real_id'] == df_walks.loc[df_walks['walker_id'] == walker_id2].iloc[0]['real_id']:\n",
    "                isPos = True\n",
    "            else:\n",
    "                isPos = False\n",
    "            \n",
    "            new_prob = 0\n",
    "            \n",
    "            # direct\n",
    "            this_prob = utils.get_direct_prob(prob_agent_id, agent_id1, agent_id2)\n",
    "            new_prob += this_prob\n",
    "            res += 'direct: ' + str(this_prob)\n",
    "            thisX.append(this_prob)\n",
    "\n",
    "            # distance\n",
    "            timec1, timec2 = utils.get_last_2_time(df_contacts, walker_id2)\n",
    "            if not timec1 or not timec2:\n",
    "                vx2, vy2 = vx, vy\n",
    "            else:\n",
    "                last_rows2 = df_contacts.loc[(df_contacts['walker_id'] == walker_id2) & (df_contacts['time'] == timec1)]\n",
    "                pre_rows2 = df_contacts.loc[(df_contacts['walker_id'] == walker_id2) & (df_contacts['time'] == timec2)]\n",
    "                if last_rows2.shape[0] == 0 or pre_rows2.shape[0] == 0:\n",
    "                    vx2, vy2 = vx, vy\n",
    "                else:\n",
    "                    vx2, vy2 = utils.get_mean_v(last_rows2, pre_rows2)\n",
    "            avg_dis2 = math.sqrt(vx2 ** 2 + vy2 ** 2)\n",
    "            \n",
    "            this_prob = utils.get_dis_prob(json1, json2, (vx+vx2)/2, (vy+vy2)/2, prob_move[agent_id1] if agent_id1 in prob_move else None,\n",
    "                                           avg_dis=(avg_dis+avg_dis2)/2, time=int(row2['time']) - int(row1['time']))\n",
    "            if this_prob <= 1e-10:\n",
    "                continue\n",
    "            new_prob += this_prob\n",
    "            thisX.append(this_prob)\n",
    "            res += ', distance: ' + str(this_prob)\n",
    "\n",
    "            # direction\n",
    "            this_prob = utils.get_direction_prob(json1, json2, prob_dir, agent_id1)\n",
    "            thisX.append(this_prob)\n",
    "            new_prob += this_prob\n",
    "            res += ', directions: ' + str(this_prob)\n",
    "                \n",
    "            if DEBUG: print(res)\n",
    "                \n",
    "            if isPos:\n",
    "                posX.append(thisX)\n",
    "                posY.append(1)\n",
    "            else:\n",
    "                negX.append(thisX)\n",
    "                negY.append(0)\n",
    "        if DEBUG: print(f'candidates', time.time() - start_time)\n",
    "            \n",
    "        return posX, posY, negX, negY\n",
    "#     if i % 100 == 99: print(f'{i+1}th/{len(walker_ids)} iter: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "p = Pool(10)\n",
    "walker_ids = set(df_contacts['walker_id'].tolist())\n",
    "print(len(walker_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = p.map(train, walker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posX, posY, negX, negY = [], [], [], []\n",
    "for tmp in results:\n",
    "    if tmp is None:\n",
    "        continue\n",
    "    tposX, tposY, tnegX, tnegY = tmp\n",
    "    posX += tposX\n",
    "    posY += tposY\n",
    "    negX += tnegX\n",
    "    negY += tnegY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917,) (6056,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(posY).shape, np.array(negY).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choices = np.random.choice(np.array(posY).shape[0], np.array(negY).shape[0], replace=False)\n",
    "# choices = np.random.choice(np.array(negY).shape[0], np.array(posY).shape[0], replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npX = np.append(np.array(negX), np.take(np.array(posX), choices, 0), axis=0)\n",
    "# npY = np.append(np.array(negY), np.take(np.array(posY), choices, 0))\n",
    "\n",
    "# npX = np.append(np.array(posX), np.take(np.array(negX), choices, 0), axis=0)\n",
    "# npY = np.append(np.array(posY), np.take(np.array(negY), choices, 0))\n",
    "\n",
    "npX = np.append(np.array(posX), np.array(negX), axis=0)\n",
    "npY = np.append(np.array(posY), np.array(negY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('X.txt', 'w') as f:\n",
    "#     for item in npX:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "# with open('Y.txt', 'w') as f:\n",
    "#     for item in npY:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8684927577800086"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, max_iter=500).fit(npX, npY)\n",
    "clf.predict(npX[:2, :])\n",
    "clf.predict_proba(npX[:2, :])\n",
    "clf.score(npX, npY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect('../corona-sniffer/backend/data/database_10_train.db')\n",
    "\n",
    "df_walks = pd.read_sql_query(\"SELECT * FROM walks JOIN walkers ON walkers.id = walks.walker_id\", cnx)\n",
    "df_walkers = pd.read_sql_query(\"SELECT * FROM walkers\", cnx)\n",
    "df_agents = pd.read_sql_query(\"SELECT * FROM agents\", cnx)\n",
    "df_contacts_tmp = pd.read_sql_query(\"SELECT * FROM contacts\", cnx)\n",
    "idx = df_contacts_tmp.groupby(['walker_id', 'time'])['distance'].transform(min) == df_contacts_tmp['distance']\n",
    "df_contacts = df_contacts_tmp[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get counter of agent_id Key -> agent_id Values\n",
    "\"\"\"\n",
    "id_to_pos, pos_to_id = utils.get_position(df_agents)\n",
    "prob_agent_id = utils.map_prob_to_agent_id(prob_pos, pos_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1590, 2: 595, 3: 301, 4: 180, 5: 117, 6: 96, 7: 68, 8: 56, 10: 27, 11: 25, 12: 25, 9: 25, 13: 24, 14: 23, 16: 11, 18: 11, 15: 10, 20: 9, 22: 8, 17: 8, 29: 7, 19: 6, 25: 6, 27: 4, 51: 4, 39: 4, 26: 3, 37: 3, 21: 3, 32: 3, 23: 3, 62: 2, 34: 2, 41: 2, 30: 2, 24: 2, 28: 2, 40: 2, 42: 2, 46: 2, 290: 1, 52: 1, 100: 1, 31: 1, 38: 1, 162: 1, 33: 1, 54: 1, 56: 1, 379: 1, 74: 1, 131: 1, 82: 1, 36: 1, 91: 1, 48: 1, 65: 1, 324: 1, 68: 1, 70: 1, 205: 1, 336: 1, 50: 1, 59: 1, 166: 1})\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# agent_id -> next_agent_id\n",
    "sparse data\n",
    "\"\"\"\n",
    "print(collections.Counter([i for dic in prob_agent_id.values() for _, i in dic.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 {'1614181', '1614415', '1614572', '1614328', '1614045', '1614201', '1614364', '1614184', '1614381', '1614032', '1614028', '1614568', '1614405', '1614100', '1614340', '1614361', '1614465', '1614441', '1614175', '1614268', '1614235', '1614115', '1614541', '1614585', '1614165', '1614448', '1614604', '1614345', '1614561', '1614595', '1614088', '1614241', '1614484', '1614481', '1614021', '1614148', '1614040', '1614392', '1614601', '1614124', '1614220', '1614388', '1614160', '1614295', '1614152', '1614520', '1614064', '1614321', '1614212', '1614285', '1614301', '1614332', '1614544', '1614092', '1614452', '1614535', '1614580', '1614055', '1614061', '1614355', '1614280', '1614460', '1614261', '1614208', '1614272', '1614121', '1614508', '1614244', '1614304', '1614105', '1614525', '1614141', '1614475', '1614501', '1614400', '1614081', '1614424', '1614225'}\n",
      "209\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\"\"\"\n",
    "Map agent id to its most possible next agent.\n",
    "\"\"\"\n",
    "link_list = {}\n",
    "all_times = sorted(list(int(time) for time in set(df_contacts['time'])))\n",
    "first_batch_times = set()\n",
    "\n",
    "for time in all_times:\n",
    "    if time < all_times[0] + UPDATE_TIME:\n",
    "        first_batch_times.add(str(time))\n",
    "        \n",
    "print(len(first_batch_times), first_batch_times)\n",
    "print(len(set(df_contacts['walker_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "walker_ids = set(df_contacts['walker_id'].tolist())\n",
    "\n",
    "# for walker_id in walker_ids:\n",
    "#     last_time = df_contacts.loc[df_contacts['walker_id'] == walker_id].sort_values('time').iloc[-1]['time']\n",
    "#     candidates = df_contacts.loc[(df_contacts['walker_id'] != walker_id) &\n",
    "#                                  (df_contacts['time'] == str(int(last_time) + INTERVAL))]\n",
    "#     if candidates.shape[0] == 1:\n",
    "#         link_list[walker_id] = candidates.iloc[-1]['walker_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Connect each linked path into a single path\n",
    "# \"\"\"\n",
    "# graph = nx.Graph([(i, j) for i, j in link_list.items() if i and j])\n",
    "# connected_components = sorted(nx.connected_components(graph), key=len, reverse=True)\n",
    "# print(len(connected_components))\n",
    "# # print(connected_components)\n",
    "\n",
    "# tried = 0\n",
    "# for i, component in enumerate(connected_components):\n",
    "#     new_id = i\n",
    "#     time_set = set()\n",
    "#     for c in component:\n",
    "#         rows = df_contacts.loc[df_contacts['walker_id'] == c]\n",
    "            \n",
    "#         tried += df_contacts.loc[df_contacts['walker_id'] == c].shape[0]\n",
    "#         df_contacts = df_contacts.replace({'walker_id': {c: str(new_id) + 'tmp'}})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_contacts['walker_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 209\n"
     ]
    }
   ],
   "source": [
    "first_batch_walkers = set(df_contacts.loc[df_contacts['time'].isin(first_batch_times)]['walker_id'])\n",
    "print(len(first_batch_walkers), len(set(df_contacts['walker_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: ['phTBKLHHZzkknnkiHNMw', 'IxwuxUWvLxxPnMsHDjun', 'ZGdSoHhdAyVULXBvEyHo', 'fpxrXCdUYvwjUwNHSdpw', 'XCvxVRpVosAILleFRuTv', 'KkwyMgvUoQGYINfrNCDZ', 'jvkwsVpbHAsIyRxikNzn', 'YwZHZWpcYkZxvssPzRDS', 'jlSOedOEHoCnONanEnxC'], 9: ['jkryylTzRzSlVxALfacJ', 'KqfjlLhGZjASYFfyhtXg', 'UYggihPiaxgKPvQHVTHE', 'EnCpKcWGoROedDPWGKQr', 'ZkoYLnMsCrXjDJYTlktd', 'AYNPmlhRlZxiVLholYNb', 'WRZiTzEejNxvLXIbjzkW', 'FVgZViNgLYTDVvUrysoY', 'bpVRPeeGLkacRMwJvaBE', 'MarLOZuMNPZNeWjQZKFP'], 14: ['ZBguRLghsVPchXDHcADz', 'rlZaUQmfRBeSByyaSGjH', 'UxiTPXkyxqbrCYxYVEDt', 'SWrWgRegRqCsUqDgvnTS', 'SamagrasQvAfSmGSFSbf', 'KoPBPtFGBJwBwzKIYvCI'], 73: ['VYRjUkcdvFwhpzMydqMi'], 30: ['xgqLFkZXrIcRpYTSkWYj', 'yMdYZqsYCwfCnxzoFUgm', 'nBNhNjGqdpZFYdeyduZl'], 1: ['qwMelPSUlliiuhRkcikA', 'ftbVlmkQUiqwZyiLlZzx', 'bySKJtOuDLDWUhNDaYEb', 'mzRGkkqMnxCokMEiokKs', 'atoURtvMuXxbLkAuxlUw', 'AdcMjFQsYiLoncrIjatQ', 'SyXdJDtUvZEuzyrtBaHq', 'dYskcEAZiAmwkafmHVat', 'KNoBiJnComEYYbFxiUwh', 'aTUqKCesJkeDxnrMCTXv', 'cONyhZNLiCzTnOEJKjWp'], 10: ['BiOefNUxnAfTahPBstVC', 'WhGVpPPhAPiabCfPOmqD', 'qYAUiFcOtkYHUHLVHhYj', 'wzpLsFueyKvnewDkhpQG', 'fvsYNqfRCYdWbQbopWJt', 'PgyXjrdGCCZnvOWNkHYN'], 85: ['UAcogifnoHDHPXCILLxQ', 'RMgvMOVlaSdQgZAlgSBO'], 17: ['TYCuePsUqZFtFJHfdMDD', 'jadbtwCLXwmCLdIBlMsL', 'dVBlhKWROcPPwkMTKPpa', 'KOgMyPxZNfwwfXxztJeY', 'YRYVPFYFapHCsGcRIQXW', 'XxFzYSMlnaSHWNQwGPFu', 'BhbtqqwFeslxcrUatRQC'], 20: ['YzEtfbPDFgaSSKqZEzwo', 'alPVCRJgWIHrrfddBOjF'], 27: ['GGnjfbVInUDQCxZJkVsg', 'JhOhDzLsuPZWctEsPFzv'], 32: ['qNGmjDDKjkLyQllDpAWQ', 'dpkOhXTQQivxfKDcJGUF', 'OgyUSjyhFgYAjQFsmTAl'], 23: ['eddVMcNBpYzjxzahVhsm', 'fUZVKnrGyRqCwENJWaOO', 'DfoQyXYGNlbIXfZMDvIH', 'lioHAPnuigvMreAAKYKz'], 19: ['wRiioycczTlsZdGbQjun', 'yAgJExkRtEXVzSgqHUYZ', 'OTCkkYqrcCJxGcOgbulB', 'sbwVKxgqBrKBHayqciuU'], 6: ['RyXfBXeAzFdXlCRXIIoM', 'skFmiWXkQsLFvuaZdNOF', 'DjyzBkAqRtZGxEZIlqxn', 'eccYQvjMQwCsNatahEHu', 'JEcMdlINaHKWsVkfawYG', 'ZvysQpkDhUCqnRyexYlX', 'xQwtTdsXLqFznmeGnWGl'], 7: ['yKEKlDmMpGaDqvtSSoQN', 'rRyzIyKLjpeKJTiCMdBV', 'qnvoydcQxMIQtczMaYgI', 'oEWvlkFVerFzjuEHKViu', 'XsZRhSNnRHqRLMDEcrqK', 'KLTMfMaFiJAXwewRgtTC', 'CFSEzzuuvFDUNzTFSmLg'], 0: ['THwcumhArxyIJIngIOme', 'sxhJXCuXpeAdzGzDxiuj', 'XkaNPsExXatPmwRGibbi', 'XAmtKtWuFipRbQEgMTwa', 'DvPiPxEjxWNArQPaYHHr', 'zukhKRVqSeAfhDVPAudi', 'nGjZkjrvjzhaZQrZswqT', 'cBbbkHLTiCzgvtyJwVMA', 'TbZvwmHBYRwEtRMhmIvG', 'oxwOZTolpZJLzhvYNKcJ'], 13: ['RlknAVvtDOCtKxGJDeQd', 'NKXjdSbZRjOeXfPYkvmE', 'mDtPekcpRKMxZGaRypTL', 'KidWxOYDiNamGptOrqJY', 'wBQYwNKHhChNNpdlLcHV'], 18: ['JkDvFBqvxXYcyrDZjrDb', 'zkBerDglXiQHgsCnSFha', 'sglwiXmXPLznfpqIeutA', 'uwNQWPbJomUiGzWOomaL'], 35: ['RolaBfgMfaKTUxOPmbaJ'], 39: ['ZBzcjotlUYgfAsCSdOqd', 'CpTlSTBQMFSCfidaKBko'], 24: ['uIGYLuTfnnFQIoiiwhPF', 'KqWQokkfjAhcjHwVizmU', 'PWQoJCRqMYdaGzJNqsgx', 'crrzVbLdnpapqjbqngZb'], 33: ['nJAuOWjYlBpbjUpuHort', 'xZHGLLbpHqfUUAHFyYen', 'bGwXDXcKDzFOiqkKsgqg'], 34: ['lOcFicpHXvnczvcgJYOp', 'IfZXsyJeiGOcRtrqdGxv', 'FOSZbMRgshUspQZufoFv'], 81: ['LdCBGoEIaFpKUKmcYllR'], 36: ['GwwUZNtoJyxxfQyetJJn', 'RuJdIMyGFusbkgFjbnvR'], 12: ['NNNJtgzlGyzRkieAkwix', 'WCUPnvfgIxQlmNLSWpQl', 'qhzRMnPrfblpjWzJFcZx', 'BpndMhIxEThkYIojdeEa', 'xhUfvlvdskLnHtZRtMnR'], 37: ['mDCwHkkjPMeXSFikdLSL', 'WqfaHZzZBziJNAJeVZoh'], 16: ['HYyqstizohpqzBPHGROs', 'HwyaiYOPeeEswUYCqitI', 'WcrWjlcTCeSNIDfjqYbu', 'xBnONImwAKCQrqdxSgqj', 'iTNsDUelwvHiZGoDGvPa'], 80: ['vnNCQJhrEyronxRulwjl'], 3: ['nBbxVxdPbljOkvIuFSuT', 'nJIifarSjWQpTSQXTqTB', 'RQnjxIKFLZhzDeFSPddA', 'dOMeEUEyjMDtPTzByxjL', 'LWlFJBJIvHpoFHkEgDzp', 'mhshGFdWOnWwhmQFwGqP', 'bHmgAoaGCDaKYfeKixqR', 'PfKvsgKaxcpbfRChDUFT', 'BJvoZJCMIctEraOtomep', 'aLDswQLDxvdbapdMucMV'], 5: ['tdcfYNJMqyUMrbeuKfdK', 'cREZkvykkmnHDsWBYYsF', 'PQJmoWIwAEMxeIySSEar', 'FgLQIMRzZnSrNltICmqn', 'VYgdSVoYsBjNxuTdLlWe', 'dBzEkRihatfNOzgWQmAc', 'DYnlrSoDLqwXgcZMBCfb', 'czizNgXxUUUoSOWIbwrF'], 11: ['XiDoARqLPwnRCeJpKAVg', 'jZsiEGkDEYAwmrWxIktb', 'DJyFHENnxDGjJIxaWlaX', 'sfYiYaNxfDRMCOZnnOMP', 'jbRstbKJPIpyMULOYAzO', 'pujTDcQkpLHjcVAkroee', 'JGHPRRCuYaSXFXfCDPnW'], 28: ['MyeSCIGjIEEgTxSiULJm', 'fEewGgRmdAHeRqdpVWbI', 'cEDSQjoTARVwRSlwdtUO'], 84: ['UkoTVbqYnNqUhbXcjDnR'], 75: ['PkgHmkYeNYxgVbQwWRqV'], 86: ['BIXUzUEVyBDVzMthITkl'], 77: ['cOeHAEPTudJtmRKWawmr'], 25: ['UrIXqHkkBAOYJQhBOCEI', 'qKAIgeOUbvpiCKdljsHU', 'EzRmYEuauoXFeReJlZvf', 'EwCpNKtSzLGOcVhXqefK', 'SpabhEioqhGILaDpkilx'], 29: ['YAbzdDAbNCVJrtcUXGpM', 'yRFXYWfJULXfoOTcEDZI', 'sHKBXxjhjyTRULLXdPIa'], 79: ['YckUjHXLfYGWgUYVBWIe'], 31: ['oLxvvvlZcLgGoLhPfULc', 'WhTwqeajtaQlCNGYnioG', 'gtWWWklqvsSsPIJUSGpa'], 15: ['SJObOtXHWJSTGvKWIlhj', 'vDqjrCChUEfgBMvGGCZx', 'CnXZFlxfbVJgTqUkLNqo', 'ENnjdkgcEOkrblepiDXP', 'IdxAShOjonHrrjmRFuFj'], 8: ['FOpMLKbcXQSvQOnOuuWi', 'TYNvGWsMoFiwclhrKOjj', 'XIalxIgLlEVemwZaLsLp', 'ptRkFKcZUYZOxSMSUPlB', 'ixkAOVWXnDolsNQDgukF'], 2: ['ZpgLnYPoLHlHNSTEJFDB', 'TDNoVsPKeWmBuHlHFRst', 'oYiWVbCesJkDCAPAikoP', 'ZLbsBpjSlNTQGIUFsNCR', 'ZaUxskGfuDBZzKpjoLfJ', 'zCcrBcuxoWegiNRiAVAQ', 'wkaKuqWbSYAPzSCfrslo', 'PvQMUVwzEiVZFuQdXEUD', 'judAHTDqiMkWqKbczVfE'], 76: ['RYIeDMfcXkfkPTvSmjmb'], 26: ['vKGfkAdScTIeSFkbexkC', 'mRQNTwjjlnYItbOSlYDq', 'mekgSuyhnCoMQxohDGGW'], 74: ['JMJaYdUYBJzqRWVcBbwm'], 38: ['fouxLGPrCTVKHMDTeeZt', 'RaPlxrXAcsJdqbDFBhWy'], 21: ['FMkfJmuAUjBOltHkFbsp'], 22: ['EqYznyYqodehnuVjqIpf', 'vZxKZblEwrvsLpZYOXxN', 'nUxWwkMFKJOZgWoZzwXe'], 82: ['tLRHcOJKDhYePnQTJGhl'], 83: ['diQggsRytVrOWYsNwBJn'], 78: ['unMXEjMAhpeOJfFbczBt']}\n"
     ]
    }
   ],
   "source": [
    "walker_ids = set(df_contacts['walker_id'])\n",
    "batched_walker_ids = collections.defaultdict(list)\n",
    "for walker_id in walker_ids:\n",
    "    time = df_contacts.loc[df_contacts['walker_id'] == walker_id].sort_values('time').iloc[-1]['time']\n",
    "    batched_walker_ids[math.floor((int(time) - all_times[0]) / UPDATE_TIME)].append(walker_id)\n",
    "print(dict(batched_walker_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNoBiJnComEYYbFxiUwh', 'mzRGkkqMnxCokMEiokKs', 'cBbbkHLTiCzgvtyJwVMA', 'AdcMjFQsYiLoncrIjatQ', 'XAmtKtWuFipRbQEgMTwa', 'TbZvwmHBYRwEtRMhmIvG', 'XkaNPsExXatPmwRGibbi', 'bySKJtOuDLDWUhNDaYEb', 'zukhKRVqSeAfhDVPAudi', 'nGjZkjrvjzhaZQrZswqT', 'sxhJXCuXpeAdzGzDxiuj', 'THwcumhArxyIJIngIOme', 'ftbVlmkQUiqwZyiLlZzx', 'atoURtvMuXxbLkAuxlUw', 'DvPiPxEjxWNArQPaYHHr', 'cONyhZNLiCzTnOEJKjWp', 'oxwOZTolpZJLzhvYNKcJ'}\n",
      "no candidates\n",
      "14 17\n",
      "{'KNoBiJnComEYYbFxiUwh', 'ZpgLnYPoLHlHNSTEJFDB', 'ZaUxskGfuDBZzKpjoLfJ', 'AdcMjFQsYiLoncrIjatQ', 'wkaKuqWbSYAPzSCfrslo', 'bySKJtOuDLDWUhNDaYEb', 'dYskcEAZiAmwkafmHVat', 'sxhJXCuXpeAdzGzDxiuj', 'ZLbsBpjSlNTQGIUFsNCR', 'ftbVlmkQUiqwZyiLlZzx', 'atoURtvMuXxbLkAuxlUw', 'zCcrBcuxoWegiNRiAVAQ', 'cONyhZNLiCzTnOEJKjWp', 'SyXdJDtUvZEuzyrtBaHq'}\n",
      "no candidates\n",
      "no candidates\n",
      "12 14\n",
      "{'ZpgLnYPoLHlHNSTEJFDB', 'nBbxVxdPbljOkvIuFSuT', 'wkaKuqWbSYAPzSCfrslo', 'BJvoZJCMIctEraOtomep', 'LWlFJBJIvHpoFHkEgDzp', 'dYskcEAZiAmwkafmHVat', 'ZLbsBpjSlNTQGIUFsNCR', 'oYiWVbCesJkDCAPAikoP', 'zCcrBcuxoWegiNRiAVAQ', 'mhshGFdWOnWwhmQFwGqP', 'SyXdJDtUvZEuzyrtBaHq', 'PvQMUVwzEiVZFuQdXEUD'}\n",
      "no candidates\n",
      "no candidates\n",
      "10 12\n",
      "{'PvQMUVwzEiVZFuQdXEUD', 'nBbxVxdPbljOkvIuFSuT', 'aLDswQLDxvdbapdMucMV', 'BJvoZJCMIctEraOtomep', 'XCvxVRpVosAILleFRuTv', 'oYiWVbCesJkDCAPAikoP', 'YwZHZWpcYkZxvssPzRDS', 'mhshGFdWOnWwhmQFwGqP', 'jlSOedOEHoCnONanEnxC', 'ZGdSoHhdAyVULXBvEyHo'}\n",
      "no candidates\n",
      "no candidates\n",
      "8 10\n",
      "{'VYgdSVoYsBjNxuTdLlWe', 'aLDswQLDxvdbapdMucMV', 'XCvxVRpVosAILleFRuTv', 'DYnlrSoDLqwXgcZMBCfb', 'YwZHZWpcYkZxvssPzRDS', 'oYiWVbCesJkDCAPAikoP', 'jlSOedOEHoCnONanEnxC', 'dBzEkRihatfNOzgWQmAc'}\n",
      "no candidates\n",
      "7 8\n",
      "{'VYgdSVoYsBjNxuTdLlWe', 'aLDswQLDxvdbapdMucMV', 'DYnlrSoDLqwXgcZMBCfb', 'DjyzBkAqRtZGxEZIlqxn', 'xQwtTdsXLqFznmeGnWGl', 'JEcMdlINaHKWsVkfawYG', 'dBzEkRihatfNOzgWQmAc'}\n",
      "no candidates\n",
      "6 7\n",
      "{'qnvoydcQxMIQtczMaYgI', 'CFSEzzuuvFDUNzTFSmLg', 'DjyzBkAqRtZGxEZIlqxn', 'yKEKlDmMpGaDqvtSSoQN', 'xQwtTdsXLqFznmeGnWGl', 'JEcMdlINaHKWsVkfawYG'}\n",
      "6 6\n",
      "{'qnvoydcQxMIQtczMaYgI', 'CFSEzzuuvFDUNzTFSmLg', 'yKEKlDmMpGaDqvtSSoQN', 'FOpMLKbcXQSvQOnOuuWi', 'rRyzIyKLjpeKJTiCMdBV', 'XIalxIgLlEVemwZaLsLp'}\n",
      "no candidates\n",
      "5 6\n",
      "{'WRZiTzEejNxvLXIbjzkW', 'FOpMLKbcXQSvQOnOuuWi', 'ZkoYLnMsCrXjDJYTlktd', 'rRyzIyKLjpeKJTiCMdBV', 'XIalxIgLlEVemwZaLsLp'}\n",
      "no candidates\n",
      "4 5\n",
      "{'ZkoYLnMsCrXjDJYTlktd', 'BiOefNUxnAfTahPBstVC', 'WRZiTzEejNxvLXIbjzkW', 'PgyXjrdGCCZnvOWNkHYN'}\n",
      "no candidates\n",
      "3 4\n",
      "{'BiOefNUxnAfTahPBstVC', 'pujTDcQkpLHjcVAkroee', 'PgyXjrdGCCZnvOWNkHYN'}\n",
      "no candidates\n",
      "2 3\n",
      "{'jbRstbKJPIpyMULOYAzO', 'pujTDcQkpLHjcVAkroee'}\n",
      "no candidates\n",
      "1 2\n",
      "{'jbRstbKJPIpyMULOYAzO'}\n",
      "no candidates\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\"\"\"\n",
    "Map agent id to its most possible next agent.\n",
    "\"\"\"\n",
    "batched_walker_ids = [first_batch_walkers]\n",
    "\n",
    "for walker_ids in batched_walker_ids:\n",
    "    print(walker_ids)\n",
    "    next_batch_ids = set()\n",
    "    for walker_id1 in walker_ids:\n",
    "        time1, time2 = utils.get_last_2_time(df_contacts, walker_id1)\n",
    "        if not time1 or not time:\n",
    "            continue\n",
    "        last_rows = df_contacts.loc[(df_contacts['walker_id'] == walker_id1) & (df_contacts['time'] == time1)]\n",
    "        pre_rows = df_contacts.loc[(df_contacts['walker_id'] == walker_id1) & (df_contacts['time'] == time2)]\n",
    "        if last_rows.shape[0] == 0 or pre_rows.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        # among all the tracked records, consider mean velocity as real velocity\n",
    "        vx, vy = utils.get_mean_v(last_rows, pre_rows)\n",
    "        avg_dis = math.sqrt(vx ** 2 + vy ** 2)\n",
    "\n",
    "        # get candidate points by time\n",
    "        candidates = df_contacts.loc[(pd.to_numeric(df_contacts[\"time\"]) == (int(time1) + INTERVAL))\n",
    "                                     & (pd.to_numeric(df_contacts[\"time\"]) > (int(time1))) \n",
    "                                     & (df_contacts['walker_id'] != walker_id1)]\n",
    "#         idx = candidates.groupby(['walker_id'])['time'].transform(lambda x: pd.to_numeric(x).min()) == pd.to_numeric(candidates['time'])\n",
    "#         candidates = candidates[idx]\n",
    "\n",
    "        if candidates.shape[0] == 0:\n",
    "            print('no candidates')\n",
    "            continue\n",
    "            \n",
    "        if candidates.shape[0] == 1:\n",
    "            link_list[walker_id] = candidates.iloc[-1]['walker_id']\n",
    "\n",
    "        candidate_agent_probs = {}\n",
    "        \n",
    "        for _, row1 in last_rows.iterrows():\n",
    "            agent_id1, time1 = row1['agent_id'], row1['time']\n",
    "            json1 = json.loads(row1['json'])['agentPos']\n",
    "\n",
    "            for _, row2 in candidates.iterrows():\n",
    "                agent_id2, walker_id2 = row2['agent_id'], row2['walker_id']\n",
    "                json2 = json.loads(row2['json'])['agentPos']\n",
    "\n",
    "                prob = utils.get_prob(df_contacts, prob_agent_id, agent_id1, agent_id2, walker_id2, \n",
    "                                      json1, json2, prob_dir, vx, vy, prob_move, int(row2['time']) - int(row1['time']))\n",
    "                next_batch_ids.add(walker_id2)\n",
    "                # a walker's probability to be the next step is the average probability\n",
    "                weight = json.loads(row2['json'])['distance']\n",
    "                prob_y = clf.predict_proba(np.array([prob])[:1, :])[0][1]\n",
    "                candidate_agent_probs[walker_id2] = utils.get_avg_prob(candidate_agent_probs, walker_id2, prob_y, weight)\n",
    "\n",
    "#         print(walker_id1, candidate_agent_probs)\n",
    "        \n",
    "        for k in candidate_agent_probs.keys():\n",
    "            if k in visited_walker_ids:\n",
    "                candidate_agent_probs[k] = (0,0)\n",
    "        correct_walker_id = max(candidate_agent_probs.items(), key=operator.itemgetter(1))[0] if candidate_agent_probs.items() else 0\n",
    "        if correct_walker_id in visited_walker_ids:\n",
    "            continue\n",
    "        link_list[walker_id1] = correct_walker_id\n",
    "        visited_walker_ids.add(correct_walker_id)\n",
    "    print(len(next_batch_ids), len(walker_ids))\n",
    "    if len(next_batch_ids) == 0:\n",
    "        break\n",
    "    batched_walker_ids.append(next_batch_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[{'KNoBiJnComEYYbFxiUwh', 'VYgdSVoYsBjNxuTdLlWe', 'PgyXjrdGCCZnvOWNkHYN', 'BJvoZJCMIctEraOtomep', 'JEcMdlINaHKWsVkfawYG', 'pujTDcQkpLHjcVAkroee', 'yKEKlDmMpGaDqvtSSoQN', 'ZLbsBpjSlNTQGIUFsNCR', 'DvPiPxEjxWNArQPaYHHr', 'ZkoYLnMsCrXjDJYTlktd', 'oxwOZTolpZJLzhvYNKcJ', 'jlSOedOEHoCnONanEnxC', 'jbRstbKJPIpyMULOYAzO', 'XIalxIgLlEVemwZaLsLp'}, {'nBbxVxdPbljOkvIuFSuT', 'qnvoydcQxMIQtczMaYgI', 'bySKJtOuDLDWUhNDaYEb', 'nGjZkjrvjzhaZQrZswqT', 'BiOefNUxnAfTahPBstVC', 'WRZiTzEejNxvLXIbjzkW', 'FOpMLKbcXQSvQOnOuuWi', 'YwZHZWpcYkZxvssPzRDS', 'xQwtTdsXLqFznmeGnWGl', 'zCcrBcuxoWegiNRiAVAQ', 'dBzEkRihatfNOzgWQmAc'}, {'cBbbkHLTiCzgvtyJwVMA', 'wkaKuqWbSYAPzSCfrslo', 'CFSEzzuuvFDUNzTFSmLg', 'XCvxVRpVosAILleFRuTv', 'DYnlrSoDLqwXgcZMBCfb', 'DjyzBkAqRtZGxEZIlqxn', 'atoURtvMuXxbLkAuxlUw', 'mhshGFdWOnWwhmQFwGqP', 'rRyzIyKLjpeKJTiCMdBV'}, {'XAmtKtWuFipRbQEgMTwa', 'aLDswQLDxvdbapdMucMV', 'oYiWVbCesJkDCAPAikoP', 'cONyhZNLiCzTnOEJKjWp', 'SyXdJDtUvZEuzyrtBaHq'}, {'LWlFJBJIvHpoFHkEgDzp', 'mzRGkkqMnxCokMEiokKs', 'ZaUxskGfuDBZzKpjoLfJ', 'ZGdSoHhdAyVULXBvEyHo'}, {'AdcMjFQsYiLoncrIjatQ', 'TbZvwmHBYRwEtRMhmIvG', 'dYskcEAZiAmwkafmHVat'}, {'XkaNPsExXatPmwRGibbi', 'ftbVlmkQUiqwZyiLlZzx', 'ZpgLnYPoLHlHNSTEJFDB'}, {'sxhJXCuXpeAdzGzDxiuj', 'zukhKRVqSeAfhDVPAudi'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Connect each linked path into a single path\n",
    "\"\"\"\n",
    "graph = nx.Graph([(i, j) for i, j in link_list.items() if i and j])\n",
    "connected_components = sorted(nx.connected_components(graph), key=len, reverse=True)\n",
    "print(len(connected_components))\n",
    "print(connected_components)\n",
    "\n",
    "tried = 0\n",
    "df_walks_connected = pd.DataFrame(df_walks)\n",
    "for i, component in enumerate(connected_components):\n",
    "    new_id = i\n",
    "    time_set = set()\n",
    "    for c in component:\n",
    "        rows = df_walks_connected.loc[df_walks_connected['walker_id'] == c]\n",
    "        \n",
    "#         cyclic = False\n",
    "#         for time in rows['walk_time'].tolist():\n",
    "#             time_set.add(time)\n",
    "            \n",
    "        tried += df_walks_connected.loc[df_walks_connected['walker_id'] == c].shape[0]\n",
    "        df_walks_connected = df_walks_connected.replace({'walker_id': {c: str(new_id) + 'res'}})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "correct/total: 1755/1771 99.09655561829474%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "How much percentage of the grouped ids are really from one group\n",
    "\"\"\"\n",
    "\n",
    "DEBUG = True\n",
    "walker_ids = set(df_walks_connected['walker_id'].tolist())\n",
    "correct, total = 0, 0\n",
    "if DEBUG: print(len(walker_ids))\n",
    "    \n",
    "for walker_id in walker_ids:\n",
    "    id_list = df_walks_connected.loc[df_walks_connected['walker_id'] == walker_id].sort_values('walk_time')['real_id'].tolist()\n",
    "    dic = collections.Counter(id_list)\n",
    "    \n",
    "    l = max(dic.values())\n",
    "    key = [k for k,v in dic.items() if v == l]\n",
    "    \n",
    "    correct += l\n",
    "    total += sum(dic.values())\n",
    "\n",
    "# print(f'correct/tried: {correct}/{tried} {correct/tried*100}%') \n",
    "print(f'correct/total: {correct}/{total} {correct/total*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct/total: 441/1771 24.90118577075099%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "How much percentage of one group is correctly grouped together (only consider the largest sub-group of grouped ids)\n",
    "\"\"\"\n",
    "\n",
    "DEBUG = False\n",
    "real_ids = set(df_walks_connected['real_id'].tolist())\n",
    "correct, total = 0, 0\n",
    "for real_id in real_ids:\n",
    "    id_list = df_walks_connected.loc[df_walks_connected['real_id'] == real_id].sort_values('walk_time')['walker_id'].tolist()\n",
    "    dic = collections.Counter(id_list)\n",
    "    if DEBUG: print(id_list)\n",
    "    \n",
    "    l = max(dic.values())\n",
    "    key = [k for k,v in dic.items() if v == l]\n",
    "    \n",
    "    correct += l\n",
    "    total += sum([v for v in dic.values()])\n",
    "#     df_walks_connected = df_walks_connected.replace({'walker_id': {key[0]: real_id}})\n",
    "# print(f'base: {total - (150 / 10 - 1) * 10}/{total} {(total - (150 / 10 - 1) * 10)/total*100}')\n",
    "# print(f'correct/tried: {correct}/{tried} {correct/tried*100}%') \n",
    "print(f'correct/total: {correct}/{total} {correct/total*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx.execute('DROP TABLE IF EXISTS walks_attached')\n",
    "df_walks_connected.to_sql('walks_attached', con=cnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Other Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = '1tmp'\n",
    "path = df_walks_connected.loc[df_walks_connected['walker_id'] == id].sort_values('walk_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-33-e4722ff0a3eb>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-e4722ff0a3eb>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    pos_to_id[(jsondict2['position']['x'], jsondict2['position']['y'])]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "for (indx1,row1),(indx2,row2) in zip(path[:-1].iterrows(),path[1:].iterrows()):\n",
    "    jsondict1, jsondict2 = json.loads(row1['json']), json.loads(row2['json'])\n",
    "    agent_id1, agent_id2 = pos_to_id[(jsondict1['position']['x'], jsondict1['position']['y'])], \n",
    "        pos_to_id[(jsondict2['position']['x'], jsondict2['position']['y'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
